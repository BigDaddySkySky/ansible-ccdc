#!/usr/bin/env python3
"""
CCDC Log Watcher Service - Hardened Edition
Monitors auth logs for suspicious activity with:
- Persistent state across reboots
- Robust error handling
- Centralized process scanning
- Structured logging

Generated by Ansible - DO NOT EDIT MANUALLY
"""

import re
import subprocess
import sys
import time
import json
import logging
from collections import defaultdict
from datetime import datetime, timedelta
from pathlib import Path

# Configuration (injected by Ansible)
WEBHOOK_URL = "{{ discord_webhook_url }}"
HOSTNAME = "{{ inventory_hostname }}"
ALERT_SCRIPT = "/usr/local/bin/ccdc_alert.py"
FAILED_LOGIN_THRESHOLD = {{ intrusion_detection_failed_login_threshold }}
FAILED_LOGIN_WINDOW = {{ intrusion_detection_failed_login_window }}
CHECK_INTERVAL = {{ intrusion_detection_log_watch_interval }}
PROCESS_SCAN_INTERVAL = 300  # 5 minutes

# Log files to monitor
{%- set os_family_key = ansible_os_family | lower -%}
{%- set monitored_logs = intrusion_detection_monitored_logs.get(os_family_key, intrusion_detection_monitored_logs.get('debian', [])) -%}

LOG_FILES = [
{% for log in monitored_logs %}
    "{{ log }}",
{% endfor %}
]

# Suspicious patterns
SUSPICIOUS_PATTERNS = [
{% for pattern in intrusion_detection_suspicious_patterns %}
    re.compile(r"{{ pattern }}"),
{% endfor %}
]

# Persistent state
STATE_FILE = Path("/var/lib/ccdc/log_watcher_state.json")
STATE_FILE.parent.mkdir(parents=True, exist_ok=True)

LOG_DIR = Path("/var/log/ccdc")
LOG_DIR.mkdir(parents=True, exist_ok=True)

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler(LOG_DIR / 'log_watcher.log'),
        logging.StreamHandler(sys.stderr)
    ]
)
logger = logging.getLogger(__name__)

# State tracking
failed_logins = defaultdict(list)  # IP -> [timestamp, ...]
last_positions = {}  # log_file -> byte_position
last_process_scan = 0

# Validate configuration
if not LOG_FILES:
    logger.critical("FATAL: No log files configured for OS family: {{ ansible_os_family }}")
    sys.exit(1)

if not WEBHOOK_URL or WEBHOOK_URL == "":
    logger.critical("FATAL: Discord webhook URL not configured")
    sys.exit(1)


def load_state():
    """Load last read positions from disk."""
    try:
        if STATE_FILE.exists():
            with open(STATE_FILE, 'r') as f:
                state = json.load(f)
                logger.info(f"Loaded state for {len(state)} log files")
                return {Path(k): v for k, v in state.items()}
    except Exception as e:
        logger.error(f"Failed to load state: {e}")
    return {}


def save_state(positions):
    """Persist read positions to disk."""
    try:
        STATE_FILE.parent.mkdir(parents=True, exist_ok=True)
        with open(STATE_FILE, 'w') as f:
            json.dump({str(k): v for k, v in positions.items()}, f)
    except Exception as e:
        logger.error(f"Failed to save state: {e}")


def get_file_position(log_file: Path) -> int:
    """Get last read position or start from end if new."""
    if log_file in last_positions:
        return last_positions[log_file]
    
    # Start from end of file for new monitors
    try:
        size = log_file.stat().st_size
        logger.info(f"Starting new monitor for {log_file} at position {size}")
        return size
    except FileNotFoundError:
        logger.warning(f"Log file not found: {log_file}")
        return 0


def read_new_lines(log_file: Path):
    """Read only new lines since last check with robust error handling."""
    try:
        current_size = log_file.stat().st_size
    except FileNotFoundError:
        logger.debug(f"Log file not found: {log_file}")
        return []
    
    last_pos = get_file_position(log_file)
    
    # Handle log rotation (file got smaller)
    if current_size < last_pos:
        logger.info(f"Log rotation detected for {log_file}, resetting position")
        last_pos = 0
    
    if current_size == last_pos:
        return []  # No new data
    
    try:
        # Use 'replace' to handle malformed UTF-8
        with open(log_file, 'r', errors='replace') as f:
            f.seek(last_pos)
            new_lines = f.readlines()
            last_positions[log_file] = f.tell()
        
        if new_lines:
            logger.debug(f"Read {len(new_lines)} new lines from {log_file}")
        
        return new_lines
        
    except Exception as e:
        logger.error(f"Error reading {log_file}: {e}")
        return []


def check_failed_logins(line: str, log_file: Path):
    """Detect failed login attempts and alert on threshold."""
    # Pattern: Failed password for USER from IP
    match = re.search(r'Failed password for (\S+) from ([\d.]+)', line)
    if not match:
        return
    
    user, ip = match.groups()
    now = datetime.now()
    
    # Add to tracking
    failed_logins[ip].append(now)
    
    # Clean old attempts outside window
    cutoff = now - timedelta(seconds=FAILED_LOGIN_WINDOW)
    failed_logins[ip] = [t for t in failed_logins[ip] if t > cutoff]
    
    # Check threshold
    if len(failed_logins[ip]) >= FAILED_LOGIN_THRESHOLD:
        alert_message = f"Failed login threshold exceeded: {len(failed_logins[ip])} attempts from {ip} for user {user}"
        send_alert("warning", alert_message, details=f"Source IP: {ip}\nUser: {user}\nLog: {log_file}\nLine: {line.strip()}")
        
        # Reset counter to avoid spam
        logger.info(f"Resetting failed login counter for {ip}")
        failed_logins[ip] = []


def check_suspicious_commands(line: str, log_file: Path):
    """Detect suspicious command patterns."""
    for pattern in SUSPICIOUS_PATTERNS:
        if pattern.search(line):
            alert_message = f"Suspicious command detected: pattern '{pattern.pattern[:50]}'"
            send_alert("critical", alert_message, 
                      details=f"Pattern: {pattern.pattern}\nLog: {log_file}\nLine: {line.strip()}")
            break  # Only alert once per line


def scan_suspicious_processes():
    """
    Centralized process scanning with deduplication.
    Replaces redundant cron job checks.
    """
    global last_process_scan
    now = time.time()
    
    if now - last_process_scan < PROCESS_SCAN_INTERVAL:
        return
    
    last_process_scan = now
    logger.debug("Running periodic process scan")
    
    suspicious_patterns = [
        (r'nc\s+-[el]', "netcat listener"),
        (r'bash\s+-i.*dev/tcp', "bash reverse shell"),
        (r'python.*socket.*connect', "python reverse shell"),
        (r'perl.*socket.*connect', "perl reverse shell"),
        (r'wget.*\|.*sh', "wget pipe to shell"),
        (r'curl.*\|.*bash', "curl pipe to bash"),
    ]
    
    try:
        ps_output = subprocess.check_output(
            ['ps', 'auxww'], 
            text=True, 
            timeout=10,
            errors='replace'
        )
        
        for pattern_str, description in suspicious_patterns:
            pattern = re.compile(pattern_str)
            matches = [line for line in ps_output.split('\n') 
                      if pattern.search(line) and 'grep' not in line]
            
            if matches:
                alert_message = f"Suspicious process detected: {description}"
                details = "\n".join(matches[:5])  # Limit to 5 matches
                send_alert("critical", alert_message, details=details)
                break  # One alert per scan
                
    except subprocess.TimeoutExpired:
        logger.error("Process scan timed out")
    except Exception as e:
        logger.error(f"Process scan failed: {e}")


def send_alert(severity: str, message: str, details: str = None):
    """Send alert via discord_alert.py script with proper error handling."""
    cmd = [
        sys.executable,
        ALERT_SCRIPT,
        "--webhook", WEBHOOK_URL,
        "--severity", severity,
        "--message", message,
        "--host", HOSTNAME
    ]
    
    if details:
        cmd.extend(["--details", details])
    
    try:
        result = subprocess.run(
            cmd, 
            timeout=15, 
            check=False,
            capture_output=True,
            text=True
        )
        
        if result.returncode != 0:
            logger.warning(f"Alert send failed (exit {result.returncode}): {result.stderr}")
        else:
            logger.info(f"Alert sent: {severity} - {message[:50]}")
            
    except subprocess.TimeoutExpired:
        logger.error("Alert send timed out")
    except Exception as e:
        logger.error(f"Failed to send alert: {e}")


def monitor_loop():
    """Main monitoring loop with robust error handling."""
    logger.info(f"CCDC Log Watcher started on {HOSTNAME}")
    logger.info(f"Monitoring {len(LOG_FILES)} log files: {', '.join(str(f) for f in LOG_FILES)}")
    logger.info(f"Check interval: {CHECK_INTERVAL}s, Process scan interval: {PROCESS_SCAN_INTERVAL}s")
    
    # Validate log files exist
    for log_file_path in LOG_FILES:
        log_file = Path(log_file_path)
        if not log_file.exists():
            logger.warning(f"Log file does not exist yet: {log_file}")
    
    iteration = 0
    
    while True:
        try:
            iteration += 1
            
            # Monitor log files
            for log_file_path in LOG_FILES:
                log_file = Path(log_file_path)
                
                if not log_file.exists():
                    continue
                
                new_lines = read_new_lines(log_file)
                
                for line in new_lines:
                    check_failed_logins(line, log_file)
                    check_suspicious_commands(line, log_file)
            
            # Periodic process scanning (replaces cron job)
            scan_suspicious_processes()
            
            # Save state every 10 iterations (reduces disk I/O)
            if iteration % 10 == 0:
                save_state(last_positions)
                logger.debug(f"State saved (iteration {iteration})")
            
            time.sleep(CHECK_INTERVAL)
            
        except KeyboardInterrupt:
            logger.info("Received interrupt signal, shutting down...")
            break
        except Exception as e:
            logger.exception(f"Error in monitoring loop: {e}")
            time.sleep(CHECK_INTERVAL)
    
    # Save state on exit
    save_state(last_positions)
    logger.info("CCDC Log Watcher stopped")


if __name__ == "__main__":
    # Load persisted state
    last_positions = load_state()
    
    # Start monitoring
    monitor_loop()
